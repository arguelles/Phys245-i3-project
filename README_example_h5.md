# HDF5 File Structure for Processed Neutrino Events

This document describes the hierarchical structure of the HDF5 files containing simulation and data of neutrino and background muon events. The goal of this script is to read event data from Apache Parquet files, preserve their original nested dictionary-like structure, and save them into a single HDF5 file. Acknowlegement: this markdown files contains chunks of text _as well as_ code generated by Generative LLMs. 

## Overall Structure

The HDF5 file is organized as follows:

-   **Root Level (`/`)**: Contains multiple groups, where each group represents a single processed event.
    -   **Event Groups (`/event_0`, `/event_1`, ..., `/event_N`)**: Each group corresponds to an individual event from the input Parquet files. The name of the group is `event_` followed by a sequential index.

## Inside an Event Group

Within each `event_X` group, the original top-level fields (which often represent different categories of information, akin to dictionaries) from the Parquet event record are stored as subgroups or datasets. For example, for a data event (non-simulation),  the HDF5 event group would contain:

-   `/event_X/mc_truth/` (subgroup)
-   `/event_X/pulses/` (subgroup)
-   `/event_X/reconstructions/` (subgroup, or dataset if it's a simple array)
-   ...and so on for other top-level fields.

### Handling Nested Data

The script recursively traverses the nested structure of the original Awkward Array records.

1.  **Dictionaries/Records**: Nested dictionaries (or Awkward Records) are converted into nested HDF5 groups. For instance, `event.mc_truth.primary_energy` would be accessible at `/event_X/mc_truth/primary_energy`.
2.  **Lists of Dictionaries/Records**: If a field is a list of dictionaries (e.g., `event.pulses` might contain a list of pulse records), a subgroup is created for that list, and each item in the list is saved as a further nested subgroup (e.g., `/event_X/pulses/item_0/`, `/event_X/pulses/item_1/`).
3.  **Homogeneous NumPy Arrays**: Standard, rectangular NumPy arrays are saved directly as HDF5 datasets with their native data types.
4.  **Jagged Arrays (Lists of Numbers)**: Lists of numbers (e.g., `[ [1, 2], [3], [4, 5, 6] ]`) are saved using `h5py.vlen_dtype`. This allows for variable-length arrays within the HDF5 dataset, preserving the jagged structure. The base data type (e.g., `np.float64` or `np.int64`) is inferred.
5.  **Complex/Inhomogeneous Data (Fallback)**: For highly complex or inhomogeneous Python objects (e.g., lists containing mixed types, or deeply nested structures that cannot be represented by `h5py.vlen_dtype`), the data is serialized to a JSON string and saved as a variable-length string dataset. This ensures that all data is preserved, though it requires deserialization when reading.

## Example Access (Python)

To access data from the generated HDF5 file using `h5py` you can consider using the following code. I asked gemini to write it for me, without having it know what the h5 files look like on the inside at all. Therefore, I guarantee it will not work out of the box. Try to use methods you see from this snippet in a jupyter environment to poke around the files first before writing up a parser.

```python
import h5py
import json
import numpy as np

output_file_path = "datafiles/0915_data_T0v3_NN_example/processed_events.hdf5"

with h5py.File(output_file_path, 'r') as f:
    # Get the first event group
    first_event_group = f['event_0'] 
    print(f"Accessing event_0:")

    # Example: Accessing a simple dataset
    if 'mc_truth' in first_event_group and 'primary_energy' in first_event_group['mc_truth']:
        energy = first_event_group['mc_truth']['primary_energy'][()]
        print(f"  Primary Energy: {energy}")

    # Example: Accessing a jagged array (e.g., pulse_times)
    if 'pulses' in first_event_group and 'pulse_times' in first_event_group['pulses']:
        pulse_times = first_event_group['pulses']['pulse_times'][()]
        print(f"  Pulse Times (first pulse): {pulse_times[0]}")
        print(f"  Type of Pulse Times: {type(pulse_times)}") # Will be a numpy array of objects (vlen_dtype)

    # You can recursively explore the group structure
    def explore_group(group, indent=0):
        for key, item in group.items():
            if isinstance(item, h5py.Group):
                print(f"{'  ' * indent}- Group: {key}/")
                explore_group(item, indent + 1)
            elif isinstance(item, h5py.Dataset):
                print(f"{'  ' * indent}- Dataset: {key}, Shape: {item.shape}, Dtype: {item.dtype}")
                # For vlen_dtype, item[()] will return a numpy array of objects
                # For JSON strings, item[()].decode('utf-8') will be needed
                # For other types, item[()] is direct